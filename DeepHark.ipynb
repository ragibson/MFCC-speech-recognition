{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "from python_speech_features import logfbank\n",
    "from python_speech_features import mfcc\n",
    "from scipy.io import wavfile\n",
    "from time import time\n",
    "import glob\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "MAX_NUM_WAVS_PER_CLASS = 2**27 - 1  # ~134M\n",
    "SAMPLE_RATE = 16000\n",
    "MFCC_SIZE = 5000\n",
    "BATCH_SIZE = 10000\n",
    "ALL_LABELS = ['yes', 'no', 'up', 'down', 'left', 'right',\n",
    "              'on', 'off', 'stop', 'go', 'unknown']\n",
    "LABEL_MAPPING = {name:i for i, name in enumerate(ALL_LABELS)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_set(filename, validation_percentage, testing_percentage):\n",
    "    \"\"\"Determines which data partition the file should belong to.\n",
    "\n",
    "    We want to keep files in the same training, validation, or testing sets even\n",
    "    if new ones are added over time. This makes it less likely that testing\n",
    "    samples will accidentally be reused in training when long runs are restarted\n",
    "    for example. To keep this stability, a hash of the filename is taken and used\n",
    "    to determine which set it should belong to. This determination only depends on\n",
    "    the name and the set proportions, so it won't change as other files are added.\n",
    "\n",
    "    It's also useful to associate particular files as related (for example words\n",
    "    spoken by the same person), so anything after '_nohash_' in a filename is\n",
    "    ignored for set determination. This ensures that 'bobby_nohash_0.wav' and\n",
    "    'bobby_nohash_1.wav' are always in the same set, for example.\n",
    "\n",
    "    Args:\n",
    "        filename: File path of the data sample.\n",
    "        validation_percentage: How much of the data set to use for validation.\n",
    "        testing_percentage: How much of the data set to use for testing.\n",
    "\n",
    "    Returns:\n",
    "        String, one of 'training', 'validation', or 'testing'.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(filename)\n",
    "    \n",
    "    # ignore anything after '_nohash_' in the file name\n",
    "    hash_name = re.sub(r'_nohash_.*$', '', base_name)\n",
    "\n",
    "    # hash(filename) -> value to split into training/testing/validation\n",
    "    hash_name_hashed = hashlib.sha1(str.encode(hash_name)).hexdigest()\n",
    "    percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                      (MAX_NUM_WAVS_PER_CLASS + 1)) *\n",
    "                     (100.0 / MAX_NUM_WAVS_PER_CLASS))\n",
    "\n",
    "    if percentage_hash < validation_percentage:\n",
    "        result = 'validation'\n",
    "    elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "        result = 'testing'\n",
    "    else:\n",
    "        result = 'training'\n",
    "    return result\n",
    "\n",
    "def convert_label_to_id(label):\n",
    "    \"\"\"Convert label to its ID for prediction.\"\"\"\n",
    "    if label not in ALL_LABELS:\n",
    "        label = 'unknown'\n",
    "    return LABEL_MAPPING[label]\n",
    "\n",
    "def pad_sound_to_one_second(data):\n",
    "    if data.shape[0] != SAMPLE_RATE:\n",
    "        padding_needed = SAMPLE_RATE - data.shape[0]\n",
    "        front_padding = padding_needed // 2\n",
    "        end_padding = padding_needed - front_padding\n",
    "        data = np.concatenate(([0]*front_padding, data, [0]*end_padding))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation count: 6798\n",
      "   testing count: 6835\n",
      "  training count: 51088\n",
      "\n",
      "11 training labels: ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "path_prefix = \"Data/train/audio/\"\n",
    "\n",
    "# Split data into 80% training, 10% validation, 10% testing\n",
    "validation_percentage = 10\n",
    "testing_percentage = 10\n",
    "datasets = {'validation': [], 'testing': [], 'training': []}\n",
    "\n",
    "for filename in glob.glob(path_prefix + \"*/*.wav\"):\n",
    "    _, _, _, label, sound_filename = filename.split(\"/\")\n",
    "    \n",
    "    if label == \"_background_noise_\":\n",
    "        continue\n",
    "    \n",
    "    dataset_name = which_set(sound_filename,\n",
    "                             validation_percentage,\n",
    "                             testing_percentage)\n",
    "    \n",
    "    # List[(label, label_id, sound_filename), ...]\n",
    "    datasets[dataset_name].append((label,\n",
    "                                   convert_label_to_id(label),\n",
    "                                   sound_filename))\n",
    "\n",
    "\n",
    "for name, labelled_sounds in datasets.items():\n",
    "    print(\"{:>10} count: {}\".format(name, len(labelled_sounds)))\n",
    "    \n",
    "# Shuffle training data to improve performance\n",
    "# random.shuffle(datasets['training'])\n",
    "\n",
    "print(\"\\n{} training labels: {}\".format(len(ALL_LABELS), ALL_LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Progress for training: 100.0%\n",
      "Import Progress for validation: 100.0%\n",
      "Import Progress for testing: 100.0%\n"
     ]
    }
   ],
   "source": [
    "def import_dataset_to_torch(name, progress=False):\n",
    "    label_ids = []\n",
    "    samples = []\n",
    "    count = 0\n",
    "    training_count = len(datasets[name])\n",
    "\n",
    "    for label, label_id, filename in datasets[name]:\n",
    "        full_path = path_prefix + label + \"/\" + filename\n",
    "        sample_rate, data = wavfile.read(full_path)\n",
    "        data = pad_sound_to_one_second(data).astype(np.int16)\n",
    "\n",
    "        assert sample_rate == SAMPLE_RATE\n",
    "        assert data.shape[0] == SAMPLE_RATE\n",
    "\n",
    "        label_ids.append(torch.LongTensor([label_id]))\n",
    "        samples.append(torch.from_numpy(data))\n",
    "\n",
    "        if progress and len(label_ids) == training_count:\n",
    "            print(\"Import Progress for {}: {:.1f}%\".format(name, 100*len(label_ids)/training_count))\n",
    "\n",
    "    samples = torch.stack(samples)\n",
    "    samples = samples.type(torch.float)\n",
    "    label_ids = torch.cat(label_ids)\n",
    "    return samples, label_ids\n",
    "\n",
    "train_samples, train_label_ids = import_dataset_to_torch('training', progress=True)\n",
    "validation_samples, validation_label_ids = import_dataset_to_torch('validation', progress=True)\n",
    "test_samples, test_label_ids = import_dataset_to_torch('testing', progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_frequency_cepstral_coefficients(file_samples):\n",
    "    \"\"\"Converts wav samples into MFCC coefficients.\n",
    "    \n",
    "    :return: numpy array of shape (num_frames, num_cep)\"\"\"\n",
    "    mfcc_feat = mfcc(file_samples, SAMPLE_RATE, winlen=0.01, numcep=50, nfilt=50)\n",
    "    fbank_feat = logfbank(file_samples, SAMPLE_RATE, winlen=0.01, nfilt=50).flatten()\n",
    "    return fbank_feat\n",
    "\n",
    "def parallel_mfcc(samples):\n",
    "    # torch.Tensor doesn't seem to be thread-safe, so we have to pass to numpy and back\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        train_mfcc = pool.map(mel_frequency_cepstral_coefficients, (row.numpy() for row in samples))\n",
    "    return [torch.from_numpy(row).type(torch.float) for row in train_mfcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved MFCCs from disk\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # If we've already computed these, retrieve them from disk\n",
    "    train_mfcc, train_id_labels = pickle.load(open(\"Data/train_mfcc.p\", \"rb\"))\n",
    "    validation_mfcc, train_id_labels = pickle.load(open(\"Data/validation_mfcc.p\", \"rb\"))\n",
    "    test_mfcc, train_id_labels = pickle.load(open(\"Data/testing_mfcc.p\", \"rb\"))\n",
    "    print(\"Retrieved MFCCs from disk\")\n",
    "    \n",
    "    if 'train_samples' in vars() or 'train_samples' in globals():\n",
    "        del train_samples\n",
    "except FileNotFoundError:\n",
    "    print(\"MFCCs not found on disk, computing...\")\n",
    "    \n",
    "    # Otherwise, compute MFCCs and store them on disk\n",
    "    start = time()\n",
    "    train_mfcc = torch.stack(parallel_mfcc(train_samples))\n",
    "    print(\"Training data MFCC took {:.1f} s\".format(time() - start))\n",
    "\n",
    "    start = time()\n",
    "    validation_mfcc = torch.stack(parallel_mfcc(validation_samples))\n",
    "    test_mfcc = torch.stack(parallel_mfcc(test_samples))\n",
    "    print(\"Validation and testing MFCC took {:.1f} s\".format(time()-start))\n",
    "    \n",
    "    pickle.dump((train_mfcc, train_label_ids),\n",
    "                open(\"Data/train_mfcc.p\", \"wb\"))\n",
    "    pickle.dump((validation_mfcc, validation_label_ids),\n",
    "                open(\"Data/validation_mfcc.p\", \"wb\"))\n",
    "    pickle.dump((test_mfcc, test_label_ids),\n",
    "                open(\"Data/testing_mfcc.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # fully connected layers:\n",
    "        #   5000->50->50->11\n",
    "        self.fc1 = nn.Linear(MFCC_SIZE, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, len(ALL_LABELS))\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "#         torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "#         torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "#         torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.leaky_relu(self.fc1(x)))\n",
    "        x = self.dropout(F.leaky_relu(self.fc2(x)))\n",
    "        x = self.dropout(F.leaky_relu(self.fc3(x)))\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(name, print_results=False):\n",
    "    # Check classification accuracy on the validation/testing set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    samples, label_ids = None, None\n",
    "    if name == 'training':\n",
    "        samples = train_mfcc\n",
    "        label_ids = train_label_ids\n",
    "    elif name == 'validation':\n",
    "        samples = validation_mfcc\n",
    "        label_ids = validation_label_ids\n",
    "    elif name == 'testing':\n",
    "        samples = test_mfcc\n",
    "        label_ids = test_label_ids\n",
    "    else:\n",
    "        assert False, \"{} not supported in accuracy\".format(name)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = net(samples)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += label_ids.size()[0]\n",
    "        correct += (predicted == label_ids).sum().item()\n",
    "    \n",
    "    percentage_correct = 100*correct/total\n",
    "    \n",
    "    if print_results:\n",
    "        # Random guessing here is 1/12 ~ 8.3%\n",
    "        print(\"Accuracy of the network on {} {} sound clips: {:.1f}%\"\n",
    "              \"\".format(len(samples), name, percentage_correct))\n",
    "    \n",
    "    return percentage_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=5000, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=11, bias=True)\n",
      "  (dropout): Dropout(p=0.1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# net = Net()\n",
    "net = torch.load(\"Data/network_state\")\n",
    "net.eval()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct for class sizes in loss function\n",
    "train_class_weights = [1/(train_label_ids == label).sum().item() for label in range(len(ALL_LABELS))]\n",
    "train_class_weights = torch.Tensor(train_class_weights)\n",
    "\n",
    "if USE_CUDA:\n",
    "    device = torch.device(\"cuda:0\" if USE_CUDA else \"cpu\")\n",
    "    net.to(device)\n",
    "    train_class_weights = train_class_weights.cuda()\n",
    "    train_class_weights.to(device)\n",
    "\n",
    "# Classification Cross-Entropy and RMSprop\n",
    "criterion = nn.CrossEntropyLoss(weight=train_class_weights)\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1: loss:    0.40431, Training accuracy:  95.7%, Validation accuracy:  81.1%, \n",
      "Epoch  101: loss:    0.40366, Training accuracy:  95.7%, Validation accuracy:  81.0%, \n",
      "Epoch  201: loss:    0.40339, Training accuracy:  95.7%, Validation accuracy:  81.1%, \n",
      "Epoch  301: loss:    0.40320, Training accuracy:  95.7%, Validation accuracy:  81.1%, \n",
      "Epoch  401: loss:    0.40306, Training accuracy:  95.8%, Validation accuracy:  81.1%, \n",
      "Finished Training in 54.03 s\n"
     ]
    }
   ],
   "source": [
    "last_validation_accuracy = 0\n",
    "start = time()\n",
    "\n",
    "for epoch in range(500): # loop over the dataset multiple times  \n",
    "    current_validation_accuracy = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_number, i in enumerate(range(0, len(train_mfcc), BATCH_SIZE)):\n",
    "        # get the inputs\n",
    "        inputs, labels = train_mfcc[i:i+BATCH_SIZE], \\\n",
    "                         train_label_ids[i:i+BATCH_SIZE]\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "#         if batch_number % 5000 == 4999: # print every 5K mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, batch_number + 1, running_loss / 5000))\n",
    "#             running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        if USE_CUDA:\n",
    "            net.to(\"cpu\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            current_training_accuracy = accuracy('training')\n",
    "            current_validation_accuracy = accuracy('validation')\n",
    "        print(\"Epoch {:>4}: loss: {:>10.5f}, \"\n",
    "              \"Training accuracy: {:>5.1f}%, \"\n",
    "              \"Validation accuracy: {:>5.1f}%, \"\n",
    "              \"\".format(epoch + 1, running_loss, current_training_accuracy, current_validation_accuracy))\n",
    "        \n",
    "#         if current_validation_accuracy < 60 or current_validation_accuracy > 0.9*last_validation_accuracy:\n",
    "#             last_validation_accuracy = current_validation_accuracy\n",
    "#         else:\n",
    "#             break\n",
    "    \n",
    "        if USE_CUDA:\n",
    "            net.to(device)\n",
    "        \n",
    "        # Shuffle training data\n",
    "#         idx = torch.randperm(train_mfcc.size()[0])\n",
    "#         train_mfcc = train_mfcc[idx]\n",
    "#         train_label_ids = train_label_ids[idx]\n",
    "\n",
    "print('Finished Training in {:.2f} s'.format(time()-start))\n",
    "\n",
    "if USE_CUDA:\n",
    "    net.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on 51088 training sound clips: 95.8%\n",
      "Accuracy of the network on 6798 validation sound clips: 81.1%\n",
      "Accuracy of the network on 6835 testing sound clips: 80.8%\n"
     ]
    }
   ],
   "source": [
    "# Check final validation and test accuracies\n",
    "_ = accuracy('training', print_results=True)\n",
    "_ = accuracy('validation', print_results=True)\n",
    "_ = accuracy('testing', print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set confusion matrix\n",
      "[0.84 0.   0.   0.   0.05 0.   0.   0.   0.   0.   0.  ]\n",
      "[0.   0.64 0.01 0.05 0.03 0.   0.01 0.   0.   0.14 0.01]\n",
      "[0.   0.01 0.68 0.   0.01 0.01 0.03 0.06 0.03 0.03 0.01]\n",
      "[0.01 0.01 0.   0.61 0.   0.   0.01 0.   0.   0.07 0.02]\n",
      "[0.03 0.01 0.   0.   0.69 0.04 0.   0.02 0.   0.   0.01]\n",
      "[0.   0.01 0.   0.   0.04 0.69 0.   0.02 0.   0.   0.01]\n",
      "[0.   0.01 0.01 0.02 0.   0.   0.63 0.01 0.   0.01 0.02]\n",
      "[0.   0.   0.07 0.   0.04 0.   0.03 0.76 0.   0.01 0.01]\n",
      "[0.   0.01 0.02 0.   0.   0.   0.   0.   0.8  0.01 0.01]\n",
      "[0.   0.12 0.03 0.04 0.   0.   0.01 0.   0.01 0.53 0.02]\n",
      "[0.12 0.17 0.18 0.26 0.14 0.25 0.28 0.13 0.15 0.2  0.89]\n",
      "\n",
      "\n",
      "Test set confusion matrix\n",
      "[0.82 0.   0.   0.   0.04 0.01 0.   0.   0.   0.   0.01]\n",
      "[0.   0.57 0.   0.06 0.01 0.   0.   0.   0.01 0.14 0.01]\n",
      "[0.01 0.02 0.67 0.   0.01 0.   0.01 0.04 0.04 0.04 0.01]\n",
      "[0.01 0.02 0.   0.58 0.   0.01 0.   0.   0.   0.02 0.02]\n",
      "[0.05 0.01 0.01 0.   0.64 0.02 0.   0.01 0.   0.02 0.01]\n",
      "[0.01 0.   0.   0.   0.02 0.69 0.   0.   0.   0.   0.02]\n",
      "[0.   0.   0.01 0.   0.   0.   0.69 0.02 0.   0.01 0.02]\n",
      "[0.01 0.01 0.01 0.   0.03 0.   0.01 0.77 0.   0.01 0.01]\n",
      "[0.   0.   0.04 0.   0.01 0.   0.   0.   0.82 0.   0.01]\n",
      "[0.   0.12 0.03 0.04 0.01 0.02 0.02 0.01 0.01 0.53 0.02]\n",
      "[0.09 0.24 0.22 0.3  0.22 0.25 0.26 0.13 0.12 0.23 0.89]\n"
     ]
    }
   ],
   "source": [
    "def print_confusion_matrix(inputs, ground_truth_labels):\n",
    "    \"\"\"Prints normalized confusion matrix with ground_truth columns and prediction rows.\"\"\"\n",
    "    confusion_matrix = np.zeros((len(ALL_LABELS), len(ALL_LABELS)), dtype=np.int)\n",
    "\n",
    "    outputs = net(inputs)\n",
    "    _, predicted_labels = torch.max(outputs, 1)\n",
    "    for ground_truth, prediction in zip(ground_truth_labels, predicted_labels):\n",
    "        confusion_matrix[prediction, ground_truth] += 1\n",
    "\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "    confusion_matrix = confusion_matrix.astype(np.float)\n",
    "    \n",
    "    for i in range(len(ALL_LABELS)):\n",
    "        confusion_matrix[:, i] = confusion_matrix[:, i] / (ground_truth_labels == i).sum().item()\n",
    "    \n",
    "    for i in range(len(ALL_LABELS)):\n",
    "        print(confusion_matrix[i, :])\n",
    "\n",
    "print(\"Validation set confusion matrix\")\n",
    "print_confusion_matrix(validation_mfcc, validation_label_ids)\n",
    "\n",
    "print(\"\\n\\nTest set confusion matrix\")\n",
    "print_confusion_matrix(test_mfcc, test_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net, \"Data/network_state\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
